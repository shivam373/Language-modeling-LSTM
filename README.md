# 📚 Language Modeling with LSTM

This project implements a **next-word prediction model** using an **LSTM-based language model** built with **TensorFlow**, **Keras**, **scikit-learn**, and **NumPy**. It's a great example of how to apply deep learning to natural language processing tasks, especially sequence prediction.

## 🚀 Features

- Train an LSTM-based language model on a custom text corpus
- Predict the next word given a sequence of words
- Built entirely using TensorFlow/Keras
- Simple and interactive Jupyter Notebook interface

## 🧠 Model Overview

The model is a sequential LSTM network that learns the structure and patterns of a text corpus and predicts the most likely next word in a given input sequence.

## 🛠️ Tech Stack

- 🧠 TensorFlow & Keras – Deep learning framework
- 📊 NumPy – Numerical operations and preprocessing
- 📈 scikit-learn – Utilities like `train_test_split`
- 📝 Jupyter Notebook – Development and experimentation

## 📂 Project Structure
Language-modeling-LSTM/
  │ 
  ├── next_word_predictor_LSTM.ipynb # Main notebook with model training & prediction 
  ├── requirements.txt # List of dependencies 
  └── README.md # Project documentation

## ✅ Installation

1. Clone the repository:

```bash
git clone https://github.com/shivam373/Language-modeling-LSTM.git
cd Language-modeling-LSTM

pip install -r requirements.txt

jupyter notebook



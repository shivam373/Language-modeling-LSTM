# ğŸ“š Language Modeling with LSTM

This project implements a **next-word prediction model** using an **LSTM-based language model** built with **TensorFlow**, **Keras**, **scikit-learn**, and **NumPy**. It's a great example of how to apply deep learning to natural language processing tasks, especially sequence prediction.

## ğŸš€ Features

- Train an LSTM-based language model on a custom text corpus
- Predict the next word given a sequence of words
- Built entirely using TensorFlow/Keras
- Simple and interactive Jupyter Notebook interface

## ğŸ§  Model Overview

The model is a sequential LSTM network that learns the structure and patterns of a text corpus and predicts the most likely next word in a given input sequence.

## ğŸ› ï¸ Tech Stack

- ğŸ§  TensorFlow & Keras â€“ Deep learning framework
- ğŸ“Š NumPy â€“ Numerical operations and preprocessing
- ğŸ“ˆ scikit-learn â€“ Utilities like `train_test_split`
- ğŸ“ Jupyter Notebook â€“ Development and experimentation

## ğŸ“‚ Project Structure
Language-modeling-LSTM/
  â”‚ 
  â”œâ”€â”€ next_word_predictor_LSTM.ipynb # Main notebook with model training & prediction 
  â”œâ”€â”€ requirements.txt # List of dependencies 
  â””â”€â”€ README.md # Project documentation

## âœ… Installation

1. Clone the repository:

```bash
git clone https://github.com/shivam373/Language-modeling-LSTM.git
cd Language-modeling-LSTM

pip install -r requirements.txt

jupyter notebook


